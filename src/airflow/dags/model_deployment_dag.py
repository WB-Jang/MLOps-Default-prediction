"""Airflow DAG for model deployment pipeline."""
from datetime import datetime, timedelta
from airflow.utils import timezone
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.sensors.python import PythonSensor
# from airflow.sensors.external_task import ExternalTaskSensor
from airflow.utils.dates import days_ago
import torch
import os
import shutil

import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from src.database.mongodb import mongodb_client
from config.settings import settings
from loguru import logger


default_args = {
    'owner': 'mlops',
    'depends_on_past': False,
    'start_date': days_ago(1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}


def check_for_approved_model(**context):
    """MongoDBì—ì„œ ë°°í¬ ëŒ€ê¸° ì¤‘ì¸(approved/retrained) ëª¨ë¸ì´ ìžˆëŠ”ì§€ í™•ì¸."""
    logger.info("Polling MongoDB for approved model...")
    
    mongodb_client.connect()
    try:
        collection = mongodb_client.get_collection("model_metadata")
        # 'deployed' ìƒíƒœê°€ ì•„ë‹ˆë©´ì„œ 'approved' ë˜ëŠ” 'retrained'ì¸ ìµœì‹  ëª¨ë¸ ê²€ìƒ‰
        latest_model = collection.find_one(
            {
                "model_name": "default_prediction_classifier", 
                "status": {"$in": ["approved", "retrained"]}
            },
            sort=[("created_at", -1)]
        )
        
        if latest_model:
            logger.info(f"âœ… Found model ready for deployment: {latest_model['model_version']}")
            # ì°¾ì€ ëª¨ë¸ ì •ë³´ë¥¼ XComì— ì €ìž¥ (ë‹¤ìŒ íƒœìŠ¤í¬ì—ì„œ ì‚¬ìš©)
            context['ti'].xcom_push(key='target_model', value={
                "model_id": str(latest_model['_id']),
                "model_path": latest_model['model_path'],
                "model_version": latest_model['model_version']
            })
            return True # Trueë¥¼ ë¦¬í„´í•˜ë©´ ì„¼ì„œê°€ ì™„ë£Œë¨
        
        logger.info("â³ No approved model found yet. Waiting...")
        return False # Falseë©´ poke_interval í›„ì— ë‹¤ì‹œ ì‹¤í–‰
        
    finally:
        mongodb_client.disconnect()

def deploy_model(**context):
    """ì„¼ì„œê°€ ì°¾ì•„ë‚¸ ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì™€ ë°°í¬ ìˆ˜í–‰."""
    ti = context['ti']
    # 1. ì„¼ì„œì—ì„œ ì „ë‹¬í•œ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    model_info = ti.xcom_pull(task_ids='sensor_wait_for_approved_model', key='target_model')
    
    if not model_info:
        raise ValueError("No model info found in XCom. Something went wrong with the sensor.")

    # 2. í•„ìš”í•œ ë³€ìˆ˜ ì •ì˜ (ì—ëŸ¬ ë°©ì§€)
    model_version = model_info['model_version']
    model_path = model_info['model_path']
    
    # ë°°í¬ ê²½ë¡œ ì„¤ì • (settings.model_save_path ì‚¬ìš©)
    deployment_dir = os.path.join(settings.model_save_path, "deployed")
    os.makedirs(deployment_dir, exist_ok=True)
    deployed_model_path = os.path.join(deployment_dir, "current_model.pth")

    logger.info(f"ðŸš€ Deploying model version: {model_version}")

    try:
        # 3. ì‹¤ì œ ë°°í¬ ìž‘ì—… (íŒŒì¼ ë³µì‚¬)
        if os.path.exists(model_path):
            shutil.copy2(model_path, deployed_model_path)
            logger.info(f"âœ… Model copied to: {deployed_model_path}")
        else:
            raise FileNotFoundError(f"Source model file not found at {model_path}")

        # 4. ë‹¤ìŒ íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë°ì´í„° ë°˜í™˜ (XCom ì €ìž¥)
        return {
            "model_id": model_info['model_id'],
            "model_version": model_version,
            "deployment_path": deployed_model_path,
            "deployment_timestamp": timezone.utcnow().isoformat()
        }

    except Exception as e:
        logger.error(f"âŒ Deployment failed: {e}")
        raise # ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ Airflowê°€ ì‹¤íŒ¨ë¡œ ì¸ì‹í•˜ê²Œ í•¨

def notify_deployment_complete(**context):
    logger.info("Deployment pipeline completed")
    ti = context['ti']
    
    # 1. include_prior_datesëŠ” ì œê±°í•˜ê³  í˜„ìž¬ DagRunì˜ ë°ì´í„°ë§Œ ì‹ ë¢°í•©ë‹ˆë‹¤.
    deployment_info = ti.xcom_pull(task_ids='deploy_model')
    
    # 2. [ë³€ê²½] ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì§„í–‰í•˜ì§€ ì•Šê³  ì—ëŸ¬ë¥¼ ë‚´ì„œ ì›ì¸ì„ íŒŒì•…í•˜ê²Œ í•©ë‹ˆë‹¤.
    if deployment_info is None:
        raise ValueError("âŒ 'deploy_model'ë¡œë¶€í„° ë°ì´í„°ë¥¼ ì „ë‹¬ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì—…ìŠ¤íŠ¸ë¦¼ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    model_ver = deployment_info['model_version']
    logger.info(f"Model {model_ver} successfully deployed")
    
    # Store notification
    mongodb_client.connect()
    try:
        notification_collection = mongodb_client.get_collection("notifications")
        notification_collection.insert_one({
            "type": "deployment_complete",
            "timestamp": timezone.utcnow(), # Airflow ê¶Œìž¥ ë°©ì‹
            "model_id": deployment_info['model_id'],
            "model_version": deployment_info['model_version'],
            "message": f"Model {deployment_info['model_version']} deployed successfully"
        })
        
        # TODO: Send actual notifications (email, Slack, etc.)
        # Example: send_slack_notification(deployment_info)
        
    finally:
        mongodb_client.disconnect()


# Define DAG
with DAG(
    'model_deployment_pipeline',
    default_args=default_args,
    schedule_interval=timedelta(days=1),
    catchup=False,
    max_active_runs=1,
    tags=['deployment', 'mongodb'],
) as dag:

    # [ë³€ê²½ë¨] ì™¸ë¶€ íƒœìŠ¤í¬ ì„¼ì„œ ëŒ€ì‹  MongoDB ì§ì ‘ ê°ì‹œ ì„¼ì„œ
    wait_for_model_sensor = PythonSensor(
        task_id='sensor_wait_for_approved_model',
        python_callable=check_for_approved_model,
        mode='reschedule',    # ì›Œì»¤ ìŠ¬ë¡¯ ë°˜ë‚© ëª¨ë“œ ìœ ì§€
        poke_interval=60,     # 1ë¶„ë§ˆë‹¤ DB í™•ì¸
        timeout=3600,         # 1ì‹œê°„ ë™ì•ˆ ì•ˆ ë‚˜ì˜¤ë©´ ì‹¤íŒ¨ ì²˜ë¦¬
    )

    deploy_task = PythonOperator(
        task_id='deploy_model',
        python_callable=deploy_model,
    )

    notify_task = PythonOperator(
        task_id='notify_deployment_complete',
        python_callable=notify_deployment_complete,
    )

    wait_for_model_sensor >> deploy_task >> notify_task